# üéôÔ∏è Alexa (Miss Heart) ‚Äî Fully‚ÄëLocal Voice Assistant

Alexa is a **fully local**, modular voice assistant that runs on Linux/Windows with your laptop microphone and speakers. It uses **OpenWakeWord**, **Whisper**, **Llama‚ÄØ3.1 via Ollama**, **Kokoro TTS**, and optional **local RAG** (LlamaIndex + FAISS) for private, real‚Äëtime voice interaction ‚Äî no cloud calls by default.

---

## üß† Highlights

- **Wake Word** via OpenWakeWord (ONNX) ‚Äî low‚Äëlatency, 16‚ÄØkHz pipeline
- **VAD + Dynamic RMS** noise gating to reduce false triggers
- **STT** with OpenAI Whisper (`small.en`, GPU‚Äëaccelerated if available)
- **LLM** with **Ollama** (default: `llama3.1:8b-instruct-q4_K_M`; alias `alexa-4k`)
- **TTS** with **Kokoro (hexgrad/Kokoro‚Äë82M)** ‚Äî fast, warm voice `af_heart`
- **Streaming LLM‚ÜíTTS**: speak partial responses immediately (SSE)
- **Local file search (RAG)** via LlamaIndex + FAISS, opt‚Äëin
- **Structured logging** for app & perf, rotating STT transcripts
- **No cloud APIs** needed for voice loop; optional web search integration

---

## üóÇÔ∏è Project Layout

```

.
‚îú‚îÄ‚îÄ main.py                     # Application loop (wake word ‚Üí STT ‚Üí LLM ‚Üí TTS)
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ microservices\_loader.py # Starts FastAPI microservices (TTS/STT/LLM)
‚îÇ   ‚îú‚îÄ‚îÄ service\_manager.py      # Spawns & tracks uvicorn processes
‚îÇ   ‚îú‚îÄ‚îÄ llm\_streaming\_server.py # LLM SSE server (/chat, /chat/stream)
‚îÇ   ‚îú‚îÄ‚îÄ stt\_service\_server.py   # STT server (/transcribe)
‚îÇ   ‚îú‚îÄ‚îÄ tts\_service\_server.py   # TTS server (/speak)
‚îÇ   ‚îú‚îÄ‚îÄ stt\_client.py           # HTTP client for STT microservice
‚îÇ   ‚îú‚îÄ‚îÄ llm\_streaming\_client.py # HTTP/SSE client + StreamingTTSIntegration
‚îÇ   ‚îú‚îÄ‚îÄ tts\_client.py           # HTTP client for TTS microservice
‚îÇ   ‚îú‚îÄ‚îÄ kwd\_service.py          # Wake-word detection w/ VAD + RMS checks
‚îÇ   ‚îú‚îÄ‚îÄ dynamic\_rms\_service.py  # Adaptive noise thresholding
‚îÇ   ‚îú‚îÄ‚îÄ llm\_service.py          # LLM flow, intents, handlers, dialog logging
‚îÇ   ‚îú‚îÄ‚îÄ llama\_indexing\_service.py / llama\_file\_search\_service.py # RAG
‚îÇ   ‚îú‚îÄ‚îÄ handlers/               # file\_search, memory, note, web\_search
‚îÇ   ‚îî‚îÄ‚îÄ logger.py               # JSON logs + colored console
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ Modelfile               # ollama model alias (alexa-4k)
‚îÇ   ‚îú‚îÄ‚îÄ system\_prompt.txt       # persona + style
‚îÇ   ‚îú‚îÄ‚îÄ llm\_responses.json      # canned strings for handlers
‚îÇ   ‚îú‚îÄ‚îÄ search\_config.json      # RAG input folders
‚îÇ   ‚îú‚îÄ‚îÄ notes.json, memory.log  # local notes & memory
‚îÇ   ‚îî‚îÄ‚îÄ sounds/kwd\_success.wav  # wake chime
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ alexa\_v0.1.onnx         # OpenWakeWord model (required)
‚îî‚îÄ‚îÄ docs/
‚îî‚îÄ‚îÄ LOGGING.md, services.md, ‚Ä¶

````

---

## üöÄ Quick Start (Linux Mint)

1) **System deps**

```bash
sudo apt-get update
sudo apt-get install -y python3-venv python3-dev portaudio19-dev ffmpeg jq
````

2. **Create env**

```bash
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip wheel
pip install -r requirements.txt
```

3. **Ollama + model**

* Install Ollama: [https://ollama.com/download](https://ollama.com/download)
* Pull base model and build alias:

```bash
ollama pull llama3.1:8b-instruct-q4_K_M
# Optional: create local alias from config/Modelfile
ollama create alexa-4k -f config/Modelfile
```

4. **Models & audio**

* Place **wake word** model at: `models/alexa_v0.1.onnx`
* Ensure the **wake chime** exists: `config/sounds/kwd_success.wav`

5. **Optional web search**

Create a `.env` in the repo root:

```bash
# NOTE: Variable name matches current code (typo kept for compatibility)
TRAVILY_API=sk_...   # Tavily Search API key
```

> ‚ö†Ô∏è Heads‚Äëup: the code expects `TRAVILY_API` (with an ‚ÄúR‚Äù). If you prefer `TAVILY_API`, update `services/web_search_service.py` accordingly.

6. **Start (microservices mode, recommended)**

```bash
python3 main.py
```

This will:

* Spawn **TTS** on `:8001`, **STT** on `:8002`, **LLM (SSE)** on `:8003`
* Load OpenWakeWord + VAD locally
* Announce readiness and listen for the wake word

Health endpoints:

* `http://127.0.0.1:8001/health` (TTS), `:8002/health` (STT), `:8003/health` (LLM)

7. **Build local RAG index (optional)**

Edit `config/search_config.json` to list folders to index, then:

```bash
python3 main.py --index
```

This creates a FAISS index in `config/faiss_index/`. You can then ask, e.g., ‚Äúfind the project map‚Äù or ‚Äúsearch docs about logging‚Äù.

---

## üó£Ô∏è How It Works (loop)

1. **Wake** ‚Äî KWD buffers 1s windows, filters with dynamic RMS + VAD, and detects the wake word.
2. **STT** ‚Äî 16‚ÄØkHz mono chunks are recorded until silence; Whisper `small.en` transcribes.
3. **LLM** ‚Äî Prompt goes to Ollama (default `alexa-4k`/llama‚ÄØ3.1). If a handler intent is detected (notes, memory, web/file search), it routes accordingly.
4. **Streaming TTS** ‚Äî The LLM SSE stream is chunked and immediately spoken by Kokoro (`af_heart`); any residual text is flushed at completion. Fallback to non‚Äëstreaming if SSE fails.

---

## ‚öôÔ∏è Configuration

* **Persona**: `config/system_prompt.txt`
* **Canned strings**: `config/llm_responses.json`
* **Notes & memory**: `config/notes.json`, `config/memory.log`
* **RAG**: `config/search_config.json`, persisted index `config/faiss_index/`
* **Wake chime**: `config/sounds/kwd_success.wav`

---

## üßæ Logs

See `docs/LOGGING.md` for full details. Key files:

* `logs/app.jsonl` ‚Äî structured app logs (all services)
* `logs/performance.jsonl` ‚Äî durations, token/s, etc.
* `logs/dialog_YYYY-MM-DD_HH-MM-SS.log` ‚Äî per‚Äësession conversations
* `logs/transcriptions.log` (+ daily rotation) ‚Äî raw STT text

Handy:

```bash
tail -f logs/app.jsonl | jq .
tail -f logs/performance.jsonl | jq .
```

---

## üîå Troubleshooting

* **No mic / ALSA warnings**: ensure `portaudio19-dev` installed; PulseAudio/JACK noise is suppressed in microservices servers.
* **Wake word not triggering**: confirm `models/alexa_v0.1.onnx` exists; reduce background noise or tweak the dynamic RMS multiplier.
* **No TTS audio**: verify default audio sink; `sd.OutputStream` uses system default.
* **SSE stalls**: check firewall (ports 8001‚Äì8003), and that `ollama serve` is reachable.
* **Web search empty**: verify `.env` key; confirm the env var name (`TRAVILY_API`) matches the code or update the code.

---

## üì¶ Requirements

* Python 3.10+
* `pyaudio`, `webrtcvad` or OpenWakeWord VAD, `numpy`
* `torch`, `openai-whisper`
* `ollama` (daemon running)
* `kokoro` (hexgrad/Kokoro-82M via `KPipeline`)
* `fastapi`, `uvicorn`, `sseclient-py`
* `llama-index`, `faiss-cpu`, `sentence-transformers`
* `requests`, `rich`, `psutil`
* (Optional) `.env` with Tavily API key

Install via:

```bash
pip install -r requirements.txt
```

---

## üõ£Ô∏è Roadmap

* Barge‚Äëin (interrupt TTS on user speech)
* Tunable KWD thresholds & per‚Äëenvironment calibration
* WebSocket/GRPC for lower‚Äëlatency streaming
* Unified config file for ports/devices/models
* Cross‚Äëplatform audio device selection UI

---

## ‚ù§Ô∏è Voice Persona

Alexa speaks in a concise, warm female voice (`af_heart`), avoids filler, and keeps responses short for voice UX.

```

---